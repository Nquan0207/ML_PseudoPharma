{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab152a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18fe640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = np.load('../data/preprocessed/train_data.npz')\n",
    "test_df = np.load('../data/preprocessed/test_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f03bd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89996, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['x_train'].shape\n",
    "# test_df['x_test'].shape\n",
    "# test_df['y_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a05e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['x_train']\n",
    "y_train = train_df['y_train']\n",
    "X_test = test_df['x_test']\n",
    "y_test = test_df['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df7dd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      1338\n",
      "           1       0.84      1.00      0.91       847\n",
      "           2       0.12      0.03      0.04       339\n",
      "           3       0.02      0.01      0.01       634\n",
      "           4       0.56      0.21      0.30      1035\n",
      "           5       0.34      0.70      0.45       592\n",
      "           6       0.00      0.00      0.00       741\n",
      "           7       0.00      0.00      0.00       421\n",
      "           8       0.46      0.87      0.60      1233\n",
      "\n",
      "    accuracy                           0.54      7180\n",
      "   macro avg       0.35      0.42      0.36      7180\n",
      "weighted avg       0.44      0.54      0.46      7180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\ADMIN\\anaconda3\\envs\\ML\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_tr_np = X_train\n",
    "y_tr_np = y_train\n",
    "X_te_np = X_test\n",
    "y_te_np = y_test\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_tr_np, y_tr_np)\n",
    "\n",
    "y_pred = clf.predict(X_te_np)\n",
    "print(classification_report(y_te_np, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f547cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87      1338\n",
      "           1       0.67      1.00      0.80       847\n",
      "           2       0.04      0.02      0.03       339\n",
      "           3       0.14      0.07      0.10       634\n",
      "           4       0.76      0.35      0.48      1035\n",
      "           5       0.22      0.39      0.28       592\n",
      "           6       0.47      0.01      0.02       741\n",
      "           7       0.00      0.00      0.00       421\n",
      "           8       0.45      0.77      0.57      1233\n",
      "\n",
      "    accuracy                           0.53      7180\n",
      "   macro avg       0.39      0.40      0.35      7180\n",
      "weighted avg       0.49      0.53      0.46      7180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "input_dim = X_train_tensor.shape[1] \n",
    "num_classes = len(torch.unique(y_train_tensor))\n",
    "model = LogisticRegressionModel(input_dim, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "epochs = 500\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    preds = outputs.argmax(dim=1)\n",
    "\n",
    "y_true = y_test_tensor.cpu().numpy()\n",
    "y_pred = preds.cpu().numpy()\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fbcd1b",
   "metadata": {},
   "source": [
    "#### Because this is the classification task, CRF does not show much effects because in general, the features are likely to be independent from each other, which is not efficient for CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a74e0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1849    0.9522    0.3097      1338\n",
      "           1     0.2105    0.0047    0.0092       847\n",
      "           2     0.0500    0.0059    0.0106       339\n",
      "           3     0.0612    0.0047    0.0088       634\n",
      "           4     0.3103    0.0087    0.0169      1035\n",
      "           5     0.1154    0.0101    0.0186       592\n",
      "           6     0.0357    0.0013    0.0026       741\n",
      "           7     0.1379    0.0095    0.0178       421\n",
      "           8     0.1364    0.0049    0.0094      1233\n",
      "\n",
      "    accuracy                         0.1823      7180\n",
      "   macro avg     0.1380    0.1113    0.0448      7180\n",
      "weighted avg     0.1565    0.1823    0.0670      7180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEQ_LEN = 20\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',                \n",
    "    max_iterations=500,              \n",
    "    all_possible_transitions=True   \n",
    ")\n",
    "\n",
    "def extract_features(vec):\n",
    "    \"\"\"Convert feature vector to dict for CRF.\"\"\"\n",
    "    return {f'f{i}': vec[i] for i in range(len(vec))}\n",
    "\n",
    "def create_sequences(X, y, seq_len=SEQ_LEN):\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    for i in range(len(X)):\n",
    "        features = {f'f{j}': str(X[i][j]) for j in range(X.shape[1])}\n",
    "        X_seq.append([features]) \n",
    "        y_seq.append([str(y[i])]) \n",
    "    return X_seq, y_seq\n",
    "\n",
    "X_train = np.array(X_train.tolist())\n",
    "y_train = np.array(y_train.tolist())\n",
    "X_test = np.array(X_test.tolist())\n",
    "y_test = np.array(y_test.tolist())\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test)\n",
    "\n",
    "crf.fit(X_train_seq, y_train_seq)\n",
    "y_pred_seq = crf.predict(X_test_seq)\n",
    "\n",
    "y_true_flat = [label for seq in y_test_seq for label in seq]\n",
    "y_pred_flat = [label for seq in y_pred_seq for label in seq]\n",
    "\n",
    "print(metrics.flat_classification_report(y_true_flat, y_pred_flat, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3435f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
